{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tabulate import tabulate\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from keras.utils.np_utils import to_categorical\n",
    "def clean_str(string):\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fairy.txt',',')\n",
    "selected = ['an2', 'text']\n",
    "non_selected = list(set(df.columns) - set(selected))\n",
    "df = df.drop(non_selected, axis=1)\n",
    "df = df.dropna(axis=0, how='any', subset=selected)\n",
    "labels = sorted(list(set(df[selected[0]].tolist())))\n",
    "dict.fromkeys(set(df[selected[0]].tolist()))\n",
    "label_dict = {}\n",
    "for i in range(len(labels)):\n",
    "    label_dict[labels[i]] = i\n",
    "\n",
    "X = df[selected[1]].apply(lambda x: clean_str(x)).tolist()\n",
    "y = df[selected[0]].apply(lambda y: label_dict[y]).tolist()\n",
    "\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_6B_50D_PATH = './glove/glove.6B.300d.txt'\n",
    "GLOVE_840B_300D_PATH = './glove/glove.840B.300d.txt'\n",
    "\n",
    "#i = 0\n",
    "\n",
    "#X, y = [], []\n",
    "#with open(TRAIN_SET_PATH, \"rb\") as infile:\n",
    "#   for line in infile:\n",
    "#       label, text = line.split(\",\")\n",
    "#        X.append(text.split())\n",
    "#        y.append(label)\n",
    "\n",
    "# X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(GLOVE_6B_50D_PATH, \"rb\") as lines:\n",
    "    word2vec = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "               for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_small = {}\n",
    "all_words = set(w for words in X for w in words)\n",
    "with open(GLOVE_6B_50D_PATH, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        parts = line.split()\n",
    "        word = parts[0]\n",
    "        nums = map(float, parts[1:])\n",
    "        if word in all_words:\n",
    "            glove_small[word] = np.array(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove Data set read\n"
     ]
    }
   ],
   "source": [
    "print('Glove Data set read')\n",
    "glove_big = {}\n",
    "with open(GLOVE_840B_300D_PATH, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        parts = line.split()\n",
    "        word = parts[0]\n",
    "        nums = map(float, parts[1:])\n",
    "        if word in all_words:\n",
    "            glove_big[word] = np.array(nums)\n",
    "\n",
    "# train word2vec on all the texts - both training and test set\n",
    "# we're not using test labels, just texts so this is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making the model\n"
     ]
    }
   ],
   "source": [
    "print('Making the model')\n",
    "model = Word2Vec(X, size=100, window=5, min_count=5, workers=2)\n",
    "#model.wv.index2word\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, model.wv.vectors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline\n"
     ]
    }
   ],
   "source": [
    "# start with the classics - naive bayes of the multinomial and bernoulli varieties\n",
    "# with either pure counts or tfidf features\n",
    "print('Pipeline')\n",
    "mult_nb = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"bernoulli nb\", BernoulliNB())])\n",
    "mult_nb_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"bernoulli nb\", BernoulliNB())])\n",
    "# SVM - which is supposed to be more or less state of the art \n",
    "# http://www.cs.cornell.edu/people/tj/publications/joachims_98a.pdf\n",
    "svc = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "svc_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"linear svc\", SVC(kernel=\"linear\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class vectorizer\n"
     ]
    }
   ],
   "source": [
    "print('Class vectorizer')\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "# and a tf-idf version of the same\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf, \n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etree\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'itervalues'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5015c44a36d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Etree'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m etree_glove_small = Pipeline([(\"glove vectorizer\", MeanEmbeddingVectorizer(glove_small)), \n\u001b[0m\u001b[1;32m      5\u001b[0m                         (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n\u001b[1;32m      6\u001b[0m etree_glove_small_tfidf = Pipeline([(\"glove vectorizer\", TfidfEmbeddingVectorizer(glove_small)), \n",
      "\u001b[0;32m<ipython-input-15-038fe899b5e8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, word2vec)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitervalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'itervalues'"
     ]
    }
   ],
   "source": [
    "# Extra Trees classifier is almost universally great, let's stack it with our embeddings\n",
    "\n",
    "print('Etree')\n",
    "etree_glove_small = Pipeline([(\"glove vectorizer\", MeanEmbeddingVectorizer(glove_small)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_glove_small_tfidf = Pipeline([(\"glove vectorizer\", TfidfEmbeddingVectorizer(glove_small)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_glove_big = Pipeline([(\"glove vectorizer\", MeanEmbeddingVectorizer(glove_big)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_glove_big_tfidf = Pipeline([(\"glove vectorizer\", TfidfEmbeddingVectorizer(glove_big)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "\n",
    "etree_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "\n",
    "##\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = [\n",
    "    (\"mult_nb\", mult_nb),\n",
    "    (\"mult_nb_tfidf\", mult_nb_tfidf),\n",
    "##    (\"bern_nb\", bern_nb),\n",
    "##    (\"bern_nb_tfidf\", bern_nb_tfidf),\n",
    "    (\"svc\", svc),\n",
    "    (\"svc_tfidf\", svc_tfidf),\n",
    "#    (\"glove_small\", etree_glove_small), \n",
    "#    (\"glove_small_tfidf\", etree_glove_small_tfidf),\n",
    "#    (\"glove_big\", etree_glove_big), \n",
    "#    (\"glove_big_tfidf\", etree_glove_big),\n",
    "#    (\"w2v\", etree_w2v),\n",
    "#    (\"w2v_tfidf\", etree_w2v_tfidf),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tabulate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7a038619df54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                  for name, model in all_models], )\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#                key=lambda (_, x): -x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloatfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".4f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tabulate' is not defined"
     ]
    }
   ],
   "source": [
    "scores = sorted([(name, cross_val_score(model, X, y, cv=3).mean()) \n",
    "                 for name, model in all_models], )\n",
    "#                key=lambda (_, x): -x)\n",
    "print (tabulate(scores, floatfmt=\".4f\", headers=(\"model\", 'score')))\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1b6ea750>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "sns.barplot(x=[name for name, _ in scores], y=[score for _, score in scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15032,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15032,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(model, X, y, n):\n",
    "    #print n,' ',y\n",
    "    test_size = 1 - (n / float(len(y)))\n",
    "    print 'Test Split', test_size\n",
    "    scores = []\n",
    "    #print len(y),'pagal hpgyaa hoon',' ',test_size\n",
    "    for train, test in StratifiedShuffleSplit(n_splits=5,test_size=test_size).split(X,y):\n",
    "        X_train, X_test = X[train], X[test]\n",
    "        y_train, y_test = y[train], y[test]\n",
    "        #print 'Idhar dekho kya aata hai...'\n",
    "        #print len(y_train), len(y_test)\n",
    "        scores.append(accuracy_score(model.fit(X_train, y_train).predict(X_test), y_test))\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~MODEL:  mult_nb  ~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Split 0.787120808941\n",
      "ACCURACY :  0.594759972955\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~MODEL:  mult_nb_tfidf  ~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Split 0.787120808941\n",
      "ACCURACY :  0.597481406356\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~MODEL:  svc  ~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Split 0.787120808941\n",
      "ACCURACY :  0.591260987153\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~MODEL:  svc_tfidf  ~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Split 0.787120808941\n",
      "ACCURACY :  0.61014198783\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~MODEL:  glove_small  ~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Split 0.787120808941\n",
      "ACCURACY :  0.528397565923\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~MODEL:  glove_small_tfidf  ~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Split 0.787120808941\n",
      "ACCURACY :  0.511561866126\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~MODEL:  glove_big  ~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Split 0.787120808941\n",
      "ACCURACY :  0.542816091954\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~MODEL:  glove_big_tfidf  ~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Split 0.787120808941\n",
      "ACCURACY :  0.540128465179\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~MODEL:  w2v  ~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Split 0.787120808941\n",
      "ACCURACY :  0.457116294794\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~MODEL:  w2v_tfidf  ~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Split 0.787120808941\n",
      "ACCURACY :  0.460158891143\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train_sizes = [10, 40, 160, 640, 3200, 6400]\n",
    "train_sizes = [ 3200]\n",
    "#train_sizes = [5261, 6012, 6764]\n",
    "table = []\n",
    "for name, model in all_models:\n",
    "    print '~~~~~~~~~~~~~~~~~~~~MODEL: ',name,' ~~~~~~~~~~~~~~~~~~~~~~'\n",
    "    for n in train_sizes:\n",
    "        \n",
    "        accuracy = benchmark(model, X, y, n)\n",
    "        print 'ACCURACY : ',accuracy\n",
    "        table.append({'model': name, \n",
    "                      'accuracy': accuracy, \n",
    "                      'train_size': n})\n",
    "    print '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'\n",
    "    print ''\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
